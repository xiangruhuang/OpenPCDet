DATASET: 'SurrealDataset'
DATA_PATH: '../data/surreal'

DATA_SPLIT: {
    'train': train,
    'test': val
}

SAMPLED_INTERVAL: {
    'train': 3,
    'test': 1
}

MERGE_ALL_ITERS_TO_ONE_EPOCH: False

SEGMENTATION_CFG: {
  NUM_SEG_CLASSES: 6890,
  #USE_ONLY_SAMPLES_WITH_SEG_LABELS: False,
  #LOAD_SEG: True
}

PLANE: {
  stride: 16,
  k: 16,
  dist_thresh: 0.02,
  count_gain: 0.05,
  sigma: 0.10,
  decision_thresh: 0.002,
}

EVALUATION_LIST: ['seg']

#USE_ONLY_SAMPLES_WITH_SEG_LABELS: True

FILTER_EMPTY_BOXES_FOR_TRAIN: True
DISABLE_NLZ_FLAG_ON_POINTS: True

USE_SHARED_MEMORY: False  # it will load the data to shared memory to speed up (DO NOT USE IT IF YOU DO NOT FULLY UNDERSTAND WHAT WILL HAPPEN)
SHARED_MEMORY_FILE_LIMIT: 35000  # set it based on the size of your shared memory

DATA_AUGMENTOR:
    DISABLE_AUG_LIST: ['placeholder']
    AUG_CONFIG_LIST:
    - NAME: random_world_flip
      ALONG_AXIS_LIST: ['x', 'y']

    - NAME: random_world_rotation
      WORLD_ROT_ANGLE: [-3.14, 3.14]

    - NAME: random_world_scaling
      WORLD_SCALE_RANGE: [0.9, 1.1]

    - NAME: random_world_translation
      NOISE_TRANSLATE_STD: 0.05
      ALONG_AXIS_LIST: ['x', 'y', 'z']

POINT_FEATURE_ENCODING: {
    encoding_type: absolute_coordinates_encoding,
    used_feature_list: ['x', 'y', 'z'],
    src_feature_list: ['x', 'y', 'z'],
}

MAX_NUM_POINTS: 200000
POINT_CLOUD_RANGE: [-4, -4, -4, 4, 4, 4]

DATA_PROCESSOR:
    - NAME: shuffle_points
      SHUFFLE_ENABLED: {
        'train': True,
        'test': False
      }

    # update data_processor.grid_size, data_processor.voxel_size
    - NAME: transform_points_to_voxels
      VOXEL_SIZE: [0.03, 0.03, 0.03]
      POINT_CLOUD_RANGE: [-4, -4, -4, 4, 4, 4]
      MAX_POINTS_PER_VOXEL: 5
      MAX_NUMBER_OF_VOXELS: {
        'train': 150000,
        'test': 150000
      }
      DRY: True
